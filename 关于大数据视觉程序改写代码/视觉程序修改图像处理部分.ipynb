{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8ad25b6-f2d9-4134-9eda-7bef064c3aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import shutil\n",
    "import math\n",
    "import PIL\n",
    "import pprint\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import PIL.Image as PImage\n",
    "from PIL import ImageEnhance\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f3be85b9-d2c0-4089-b97a-8edab8755322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_BASE_URL = 'http://fireeye-test-backend-container:9090/api/'\n",
    "TF_SERVING_BASE_URL = 'http://fireeye-test-model-container:8501/'\n",
    "task_id='1ac1e8a095df4611af387d9934799251'\n",
    "id_code_mapping = {\n",
    "    'dbee3deebc5444f5b011da4e5518752c': '0',\n",
    "    'edb4cb51d54644c08aa122d3f041bb0a': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1248907f-e39a-4607-8d96-ef1b69916438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该图片数量： 318\n"
     ]
    }
   ],
   "source": [
    "num_images = requests.get(\n",
    "    url=API_BASE_URL+'image/count', \n",
    "    params=dict(\n",
    "        task_id=task_id,\n",
    "        has_truth=True\n",
    "    )\n",
    ").json()\n",
    "\n",
    "print('该图片数量：',num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "815320be-3292-4d22-99a6-1a2a4ea21dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def get_image_records(task_id):\n",
    "    resp = requests.get(\n",
    "        url=API_BASE_URL+'image', \n",
    "        params=dict(\n",
    "            task_id=task_id,\n",
    "            has_truth=True\n",
    "        )\n",
    "    )\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        raise RuntimeError(resp.text)\n",
    "\n",
    "image_records=get_image_records(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c3d05648-952f-4c26-a4d9-8208438777d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = \"./images\"\n",
    "category0_dir = os.path.join(image_dir, 'Category0')\n",
    "category1_dir = os.path.join(image_dir, 'Category1')\n",
    "if not os.path.exists(category0_dir):\n",
    "    os.makedirs(category0_dir)\n",
    "\n",
    "if not os.path.exists(category1_dir):\n",
    "    os.makedirs(category1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "58995ee8-e434-4602-9b5e-7a5b3f3e241f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_jitter(img: Image.Image, brightness=0.2, contrast=0.2, saturation=0.2) -> Image.Image:\n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + brightness * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + contrast * (2 * np.random.random() - 1))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + saturation * (2 * np.random.random() - 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f40cd53-3bfe-476e-ae56-c9242c1fa67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_image(img: Image.Image, target_size=(224, 224)) -> Image.Image:\n",
    "    return img.resize(target_size, Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "177fc6c8-184b-48d7-a90f-4d5991c87569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_image(image_id):\n",
    "    response = requests.get(f\"{API_BASE_URL}image/download/{image_id}\")\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d55601c5-7dab-4c51-8705-d1b8754423bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vertical_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.flip(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f45fa63d-790e-4a4d-8957-38d0ee14f1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.mirror(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "715e893f-aa4d-4a74-901c-74ea3d5a95a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(img: Image.Image) -> np.ndarray:\n",
    "    img_array = np.array(img)\n",
    "    return img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8dcadcb3-9073-4c2f-9c09-5037d17dccb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_by_id(id):\n",
    "    r = requests.get(url=API_BASE_URL+'image/'+id)\n",
    "    if r.status_code == 200:\n",
    "        return PIL.Image.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        raise RuntimeError(r.text)\n",
    "img = get_image_by_id(image_records[35]['id']) \n",
    "img_vertical_flipped = vertical_flip(img)\n",
    "img_horizontal_flipped = horizontal_flip(img)\n",
    "img_normalized = normalize_image(img)\n",
    "jittered_image = color_jitter(img)\n",
    "resized_image = resize_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fa48f4a4-bf8d-4d9d-a7a3-04f3639aec9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#可省略步骤，主要看看效果\n",
    "#上面一段还需要研究一下，是否删除\n",
    "img_vertical_flipped.save(\"path_to_save_vertical_flipped.png\")\n",
    "img_horizontal_flipped.save(\"path_to_save_horizontal_flipped.png\")\n",
    "jittered_image.save('path_to_save_jittered_image.png')\n",
    "resized_image.save('path_to_save_resized_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897ab2e-fd77-4eba-9a26-b8d9a8475fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in image_records:\n",
    "    image_content = download_image(record['id'])\n",
    "    truth_id = record['truth_id']\n",
    "\n",
    "    # Note: `id_code_mapping` is not defined in the provided code.\n",
    "    # Make sure it's properly defined or replaced by appropriate logic.\n",
    "    if id_code_mapping[truth_id] == '0':\n",
    "        file_path = os.path.join(category0_dir, f\"{record['id']}.png\")\n",
    "    else:\n",
    "        file_path = os.path.join(category1_dir, f\"{record['id']}.png\")\n",
    "    try:\n",
    "        img = Image.open(io.io.BytesIO(image_content))\n",
    "        img.save(file_path, 'PNG')\n",
    "    except Exception as e:\n",
    "        print(f'Error processing image {record[\"id\"]}. Error: {e}')\n",
    "\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(image_content)\n",
    "    img.save(file_path, 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e2b1ab6-a729-4c01-b6fb-413a38c8021c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image ./images/Category0/.ipynb_checkpoints. Error: [Errno 21] Is a directory: './images/Category0/.ipynb_checkpoints'\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_save_images(image_list, save_dir):\n",
    "    for image_path in image_list:\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            img_vertical_flipped = vertical_flip(img)\n",
    "            img_horizontal_flipped = horizontal_flip(img)\n",
    "            img_normalized = normalize_image(img)\n",
    "            img_resized = resize_image(img)\n",
    "            img_jittered = color_jitter(img)\n",
    "\n",
    "            base_name = os.path.basename(image_path).split('.')[0]\n",
    "            img_vertical_flipped.save(os.path.join(save_dir, f\"{base_name}_vertical_flipped.png\"))\n",
    "            img_horizontal_flipped.save(os.path.join(save_dir, f\"{base_name}_horizontal_flipped.png\"))\n",
    "            img_resized.save(os.path.join(save_dir, f\"{base_name}_resized.png\"))\n",
    "            img_jittered.save(os.path.join(save_dir, f\"{base_name}_jittered.png\"))\n",
    "\n",
    "            img_normalized_pil = Image.fromarray((img_normalized * 255).astype('uint8'))\n",
    "            img_normalized_pil.save(os.path.join(save_dir, f\"{base_name}_normalized.png\"))\n",
    "        except Exception as e:\n",
    "            print(f'Error processing image {image_path}. Error: {e}')\n",
    "\n",
    "\n",
    "\n",
    "all_category0_images = [os.path.join(category0_dir, fname) for fname in os.listdir(category0_dir)]\n",
    "all_category1_images = [os.path.join(category1_dir, fname) for fname in os.listdir(category1_dir)]\n",
    "\n",
    "preprocess_and_save_images(all_category0_images, category0_dir)\n",
    "preprocess_and_save_images(all_category1_images, category1_dir)\n",
    "\n",
    "category0_train, category0_val, category0_test = split_data(category0_dir)\n",
    "category1_train, category1_val, category1_test = split_data(category1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eacdbf68-0a79-4207-bdc2-5b81fee89ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(directory):\n",
    "    all_files = [os.path.join(directory, fname) for fname in os.listdir(directory)]\n",
    "    train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
    "    train_files, val_files = train_test_split(train_files, test_size=0.25, random_state=42)\n",
    "    return train_files, val_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29951eaa-be63-44b5-bf26-996524d5560c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9257/26416009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory0_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Category0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory0_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Category0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory0_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Category0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_files' is not defined"
     ]
    }
   ],
   "source": [
    "category0_train, category0_val, category0_test = split_data(category0_dir)\n",
    "category1_train, category1_val, category1_test = split_data(category1_dir)\n",
    "\n",
    "def move_files(file_list, target_dir):\n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "    for f in file_list:\n",
    "        shutil.move(f, target_dir)\n",
    "\n",
    "move_files(category0_train, os.path.join(train_dir, 'Category0'))\n",
    "move_files(category0_val, os.path.join(val_dir, 'Category0'))\n",
    "move_files(category0_test, os.path.join(test_dir, 'Category0'))\n",
    "\n",
    "move_files(category1_train, os.path.join(train_dir, 'Category1'))\n",
    "move_files(category1_val, os.path.join(val_dir, 'Category1'))\n",
    "move_files(category1_test, os.path.join(test_dir, 'Category1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "1c243f63-b517-4a70-bf7b-43f96dcc7ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed5e8f7e-f6fb-46ee-b0a8-1c30da386b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110d0c4c-692e-4849-88f3-cfd3a3203e71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 06:48:50.861283: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-04 06:48:50.861318: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-04 06:48:50.861336: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (58c881efe57c): /proc/driver/nvidia/version does not exist\n",
      "2023-09-04 06:48:50.862537: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#ef build_dataset(data_dir, target=None):\n",
    "#   all_images = []\n",
    "#   all_labels = []\n",
    "#   for i in range(4):\n",
    "#       if target is not None and i != target:\n",
    "#           continue\n",
    "#       images = glob.glob(os.path.join(data_dir, f'{i}/*.png'), recursive=True)\n",
    "#       all_images.extend(images)\n",
    "#       all_labels.extend([i] * len(images))\n",
    "#   ds = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "#   ds = ds.map(lambda x,y: (tf.io.encode_base64(tf.io.read_file(x)) ,y))\n",
    "#   ds = ds.shuffle(100, seed=123)\n",
    "#   ds = ds.batch(batch_size)\n",
    "#   return ds\n",
    "\n",
    "\n",
    "#rain_ds = build_dataset(train_dir)\n",
    "#ev_ds = build_dataset(dev_dir)\n",
    "#test_ds = build_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "21de717b-81f6-45f9-b92f-7b548b1f47ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_94/528246800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258aa0b3-cfe5-4340-93d3-642054ed88ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from keras import models\n",
    "#\n",
    "\n",
    "#def process_base64_image(s):\n",
    "#    img = tf.io.decode_base64(s)\n",
    "#    img = tf.io.decode_png(img, channels=3)\n",
    "#    img = tf.image.resize(img, (img_height, img_width), antialias=True)    \n",
    "#    return img\n",
    "\n",
    "#model = models.Sequential([\n",
    " #   layers.Lambda(\n",
    " #           (\n",
    "#                lambda x: tf.map_fn(\n",
    "#                    process_base64_image,\n",
    "#                    x,\n",
    "#                    fn_output_signature=tf.TensorSpec(shape=(int(img_height), int(img_width), 3), dtype=tf.float32))\n",
    "#            ),\n",
    "#            name='decode_base64_png'\n",
    "#        ),\n",
    "#    tf.keras.layers.Conv2D(32, (3, 3),  activation='relu', input_shape=(150, 150, 3)),\n",
    "#    tf.keras.layers.MaxPool2D(2, 2),\n",
    "#    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(512, activation='relu'),\n",
    "#    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "#from keras import optimizers\n",
    "#model.compile(\n",
    "#    loss='binary_crossentropy',\n",
    "#    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "#    metrics=['accuracy'])\n",
    "#model.summary()\n",
    "#model.compile(\n",
    "#  optimizer='adam',\n",
    "#  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d37fd8c4-76da-4aa1-ad9c-3cb0a4537417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_base64_image(s):\n",
    "    img = tf.io.decode_base64(s)\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, (img_height, img_width), antialias=True)    \n",
    "    return img\n",
    "\n",
    "# 构建模型\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Lambda(\n",
    "            (\n",
    "                lambda x: tf.map_fn(\n",
    "                    process_base64_image,\n",
    "                    x,\n",
    "                    fn_output_signature=tf.TensorSpec(shape=(int(img_height), int(img_width), 3), dtype=tf.float32))\n",
    "            ),\n",
    "            name='decode_base64_png'\n",
    "        ),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "567394b4-b8ca-4f1f-9585-ac7d86ac5907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bced0ca6-8207-4aad-bc2f-2f13353c3e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 12s 726ms/step - loss: 295.4449 - accuracy: 0.7134 - val_loss: 51.6766 - val_accuracy: 0.3291\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 11s 727ms/step - loss: 28.4405 - accuracy: 0.7909 - val_loss: 53.9243 - val_accuracy: 0.6709\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 11s 723ms/step - loss: 26.9080 - accuracy: 0.6293 - val_loss: 3.1529 - val_accuracy: 0.3367\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 11s 724ms/step - loss: 2.0840 - accuracy: 0.7823 - val_loss: 1.6101 - val_accuracy: 0.6709\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 11s 725ms/step - loss: 0.8889 - accuracy: 0.6034 - val_loss: 8.1377 - val_accuracy: 0.6709\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 11s 725ms/step - loss: 2.2395 - accuracy: 0.6164 - val_loss: 0.7689 - val_accuracy: 0.6709\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 11s 726ms/step - loss: 0.5435 - accuracy: 0.7091 - val_loss: 0.4800 - val_accuracy: 0.6658\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 11s 731ms/step - loss: 0.4918 - accuracy: 0.7112 - val_loss: 0.4198 - val_accuracy: 0.7092\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 11s 725ms/step - loss: 0.3808 - accuracy: 0.7608 - val_loss: 5.7604 - val_accuracy: 0.6709\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 11s 723ms/step - loss: 1.7293 - accuracy: 0.7134 - val_loss: 15.3760 - val_accuracy: 0.6709\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 11s 723ms/step - loss: 3.6328 - accuracy: 0.7177 - val_loss: 2.2004 - val_accuracy: 0.6709\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 11s 727ms/step - loss: 0.8498 - accuracy: 0.5690 - val_loss: 0.4755 - val_accuracy: 0.6735\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 11s 727ms/step - loss: 0.5128 - accuracy: 0.7198 - val_loss: 0.4462 - val_accuracy: 0.6964\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 11s 725ms/step - loss: 0.4333 - accuracy: 0.7457 - val_loss: 0.4389 - val_accuracy: 0.7194\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 11s 720ms/step - loss: 0.4664 - accuracy: 0.7414 - val_loss: 0.4106 - val_accuracy: 0.7066\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 11s 723ms/step - loss: 0.4051 - accuracy: 0.7608 - val_loss: 0.4099 - val_accuracy: 0.7474\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 11s 724ms/step - loss: 0.4047 - accuracy: 0.8147 - val_loss: 0.3734 - val_accuracy: 0.8648\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 11s 725ms/step - loss: 0.4335 - accuracy: 0.6703 - val_loss: 0.4351 - val_accuracy: 0.6862\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 11s 724ms/step - loss: 0.4743 - accuracy: 0.6142 - val_loss: 0.3984 - val_accuracy: 0.7066\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 11s 724ms/step - loss: 0.4260 - accuracy: 0.7392 - val_loss: 0.3900 - val_accuracy: 0.7015\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=dev_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c21f94d8-d1c6-4bb8-a943-566c6331b8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 220ms/step - loss: 0.3729 - accuracy: 0.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3728915750980377, 0.7134831547737122]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaee01-16b7-4bae-9036-708bc2557672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "model_version =  datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d%H%M%S')\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    f'/models/slot1/{model_version}/',\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5a911-5329-4cd7-8906-3a1cc730847f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def predict_image(images):    \n",
    "    bimages = []\n",
    "    for image in images:\n",
    "        with open(image, 'rb') as  fimage:\n",
    "            content = fimage.read()\n",
    "        bimage = base64.urlsafe_b64encode(content).decode()\n",
    "        bimages.append(bimage)\n",
    "    req_data ={\n",
    "      'inputs': bimages,\n",
    "    } \n",
    "    response = requests.post(TF_SERVING_BASE_URL+f'v1/models/slot1/versions/{model_version}:predict', # 根据部署地址填写\n",
    "                             json=req_data,\n",
    "                             headers={\"content-type\": \"application/json\"})\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "    resp_data = json.loads(response.text)    \n",
    "    if 'outputs' not in resp_data \\\n",
    "                        or type(resp_data['outputs']) is not list:\n",
    "        raise ValueError('Malformed tf-serving response')\n",
    "    outputs = np.argmax(resp_data['outputs'], axis=1).tolist()\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def test_image_model(test_dir, code, batch_size=10):    \n",
    "    images = list(pathlib.Path(test_dir).joinpath(str(code)).glob('./*.png')) \n",
    "    codes = []\n",
    "    for step in range(math.ceil(len(images)/batch_size)):\n",
    "        outputs = predict_image(images[step*batch_size:(step+1)*batch_size])\n",
    "        for i, o in zip(images, outputs):            \n",
    "            if o != code:\n",
    "                print('错误图片：', i)\n",
    "        codes.extend(outputs)\n",
    "    accuracy = round(codes.count(code) / len(codes), 4)\n",
    "    return accuracy, codes\n",
    "\n",
    "accuracy, codes = test_image_model(test_dir, 0)\n",
    "print('类别0的准确率', accuracy)\n",
    "print('类别0的测试结果', codes)\n",
    "accuracy, codes = test_image_model(test_dir, 1)\n",
    "print('类别1的准确率', accuracy)\n",
    "print('类别1的测试结果', codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cedbc6-a387-404d-b7d8-c364db52f614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
