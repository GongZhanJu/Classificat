{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853757b9-b9f5-4530-830d-398ebbf24477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f598a99-5d54-43b8-8b2f-1e7b1fc9dd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>特征0</th>\n",
       "      <th>特征1</th>\n",
       "      <th>特征2</th>\n",
       "      <th>特征3</th>\n",
       "      <th>特征4</th>\n",
       "      <th>特征5</th>\n",
       "      <th>特征6</th>\n",
       "      <th>特征7</th>\n",
       "      <th>特征8</th>\n",
       "      <th>特征9</th>\n",
       "      <th>...</th>\n",
       "      <th>特征16</th>\n",
       "      <th>特征17</th>\n",
       "      <th>补偿0</th>\n",
       "      <th>补偿1</th>\n",
       "      <th>补偿2</th>\n",
       "      <th>补偿3</th>\n",
       "      <th>补偿4</th>\n",
       "      <th>补偿5</th>\n",
       "      <th>补偿6</th>\n",
       "      <th>补偿7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4158</td>\n",
       "      <td>2.9711</td>\n",
       "      <td>10.7935</td>\n",
       "      <td>7.5279</td>\n",
       "      <td>2.3352</td>\n",
       "      <td>8.1042</td>\n",
       "      <td>2.3096</td>\n",
       "      <td>3.3367</td>\n",
       "      <td>11.8639</td>\n",
       "      <td>12.7142</td>\n",
       "      <td>...</td>\n",
       "      <td>171.764</td>\n",
       "      <td>1434.24</td>\n",
       "      <td>0.331511</td>\n",
       "      <td>-0.932553</td>\n",
       "      <td>0.285048</td>\n",
       "      <td>-0.1435</td>\n",
       "      <td>-0.833982</td>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.463969</td>\n",
       "      <td>1.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6280</td>\n",
       "      <td>1.8616</td>\n",
       "      <td>10.1770</td>\n",
       "      <td>7.4684</td>\n",
       "      <td>2.1915</td>\n",
       "      <td>8.5945</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>2.9661</td>\n",
       "      <td>11.5816</td>\n",
       "      <td>12.2487</td>\n",
       "      <td>...</td>\n",
       "      <td>185.824</td>\n",
       "      <td>1469.19</td>\n",
       "      <td>0.894066</td>\n",
       "      <td>-0.446796</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>-0.4624</td>\n",
       "      <td>0.715252</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.988844</td>\n",
       "      <td>0.689742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9648</td>\n",
       "      <td>1.8103</td>\n",
       "      <td>10.1682</td>\n",
       "      <td>5.9705</td>\n",
       "      <td>2.0629</td>\n",
       "      <td>6.5349</td>\n",
       "      <td>2.8694</td>\n",
       "      <td>3.1185</td>\n",
       "      <td>11.7464</td>\n",
       "      <td>12.2074</td>\n",
       "      <td>...</td>\n",
       "      <td>187.576</td>\n",
       "      <td>1540.76</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.460716</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>-0.4624</td>\n",
       "      <td>0.723031</td>\n",
       "      <td>0.992935</td>\n",
       "      <td>0.682903</td>\n",
       "      <td>0.749580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7119</td>\n",
       "      <td>1.6221</td>\n",
       "      <td>10.1487</td>\n",
       "      <td>6.8678</td>\n",
       "      <td>2.0694</td>\n",
       "      <td>6.8806</td>\n",
       "      <td>1.5791</td>\n",
       "      <td>2.3003</td>\n",
       "      <td>11.5545</td>\n",
       "      <td>12.0659</td>\n",
       "      <td>...</td>\n",
       "      <td>189.938</td>\n",
       "      <td>1498.29</td>\n",
       "      <td>0.998794</td>\n",
       "      <td>-0.862448</td>\n",
       "      <td>0.329694</td>\n",
       "      <td>-0.4624</td>\n",
       "      <td>0.891745</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.997127</td>\n",
       "      <td>0.984439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3797</td>\n",
       "      <td>1.6852</td>\n",
       "      <td>10.9601</td>\n",
       "      <td>5.0035</td>\n",
       "      <td>3.1659</td>\n",
       "      <td>5.9471</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>2.6402</td>\n",
       "      <td>11.7458</td>\n",
       "      <td>12.7041</td>\n",
       "      <td>...</td>\n",
       "      <td>181.275</td>\n",
       "      <td>1465.11</td>\n",
       "      <td>0.442893</td>\n",
       "      <td>-0.990703</td>\n",
       "      <td>-0.151400</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.617880</td>\n",
       "      <td>-0.506397</td>\n",
       "      <td>-0.997502</td>\n",
       "      <td>0.376126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      特征0     特征1      特征2     特征3     特征4     特征5     特征6     特征7      特征8  \\\n",
       "0  1.4158  2.9711  10.7935  7.5279  2.3352  8.1042  2.3096  3.3367  11.8639   \n",
       "1  0.6280  1.8616  10.1770  7.4684  2.1915  8.5945  0.1379  2.9661  11.5816   \n",
       "2  0.9648  1.8103  10.1682  5.9705  2.0629  6.5349  2.8694  3.1185  11.7464   \n",
       "3  0.7119  1.6221  10.1487  6.8678  2.0694  6.8806  1.5791  2.3003  11.5545   \n",
       "4  0.3797  1.6852  10.9601  5.0035  3.1659  5.9471  0.0858  2.6402  11.7458   \n",
       "\n",
       "       特征9  ...     特征16     特征17       补偿0       补偿1       补偿2     补偿3  \\\n",
       "0  12.7142  ...  171.764  1434.24  0.331511 -0.932553  0.285048 -0.1435   \n",
       "1  12.2487  ...  185.824  1469.19  0.894066 -0.446796  0.058519 -0.4624   \n",
       "2  12.2074  ...  187.576  1540.76  0.999982  0.460716  0.997809 -0.4624   \n",
       "3  12.0659  ...  189.938  1498.29  0.998794 -0.862448  0.329694 -0.4624   \n",
       "4  12.7041  ...  181.275  1465.11  0.442893 -0.990703 -0.151400  0.2245   \n",
       "\n",
       "        补偿4       补偿5       补偿6       补偿7  \n",
       "0 -0.833982  0.767568  0.463969  1.904800  \n",
       "1  0.715252  0.999105  0.988844  0.689742  \n",
       "2  0.723031  0.992935  0.682903  0.749580  \n",
       "3  0.891745  0.015078  0.997127  0.984439  \n",
       "4  0.617880 -0.506397 -0.997502  0.376126  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data.tsv',sep='\\t',skipinitialspace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c72eac-680b-4586-be07-34c6d05655dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get features and labels\n",
    "features = data.iloc[:, :18].values\n",
    "labels = data.iloc[:, 18:26].values\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "labels_scaled = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010c102c-1720-4e79-a5e8-fc819cf2a171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_size = int(len(features_scaled) * 0.7)\n",
    "val_size = int(len(features_scaled) * 0.1)\n",
    "test_size = len(features_scaled) - train_size - val_size\n",
    "\n",
    "train_features = features_scaled[:train_size, :]\n",
    "train_labels = labels_scaled[:train_size]\n",
    "\n",
    "val_features = features_scaled[train_size:train_size+val_size, :]\n",
    "val_labels = labels_scaled[train_size:train_size+val_size]\n",
    "\n",
    "test_features = features_scaled[train_size+val_size:, :]\n",
    "test_labels = labels_scaled[train_size+val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612dbcf7-8a9b-4efb-886b-98304aaa6158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create LSTM dataset\n",
    "def create_lstm_dataset(features, labels, time_steps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(features) - time_steps):\n",
    "        a = features[i:(i + time_steps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(labels[i + time_steps:i + time_steps + 1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_steps = 7\n",
    "trainX, trainY = create_lstm_dataset(train_features, train_labels, time_steps)\n",
    "valX, valY = create_lstm_dataset(val_features, val_labels, time_steps)\n",
    "testX, testY = create_lstm_dataset(test_features, test_labels, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc880e9f-db74-4369-b49e-343e0625df3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 07:56:09.248934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-08-21 07:56:09.248976: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-21 07:56:09.248991: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (58c881efe57c): /proc/driver/nvidia/version does not exist\n",
      "2023-08-21 07:56:09.249223: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 构建LSTM模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(time_steps, 18)))\n",
    "model.add(Dense(8))  # 8 output units for 8 labels\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ad4ec-9ab8-444b-bf44-5140f6de150f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4397 - val_loss: 0.4294\n",
      "Epoch 2/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4382 - val_loss: 0.4310\n",
      "Epoch 3/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4380 - val_loss: 0.4302\n",
      "Epoch 4/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4379 - val_loss: 0.4299\n",
      "Epoch 5/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4379 - val_loss: 0.4300\n",
      "Epoch 6/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4378 - val_loss: 0.4310\n",
      "Epoch 7/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4379 - val_loss: 0.4300\n",
      "Epoch 8/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4294\n",
      "Epoch 9/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4308\n",
      "Epoch 10/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4376 - val_loss: 0.4294\n",
      "Epoch 11/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4294\n",
      "Epoch 12/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4378 - val_loss: 0.4299\n",
      "Epoch 13/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4294\n",
      "Epoch 14/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4294\n",
      "Epoch 15/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4297\n",
      "Epoch 16/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4295\n",
      "Epoch 17/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4296\n",
      "Epoch 18/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4377 - val_loss: 0.4297\n",
      "Epoch 19/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4376 - val_loss: 0.4296\n",
      "Epoch 20/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4376 - val_loss: 0.4294\n",
      "Epoch 21/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4376 - val_loss: 0.4296\n",
      "Epoch 22/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4376 - val_loss: 0.4296\n",
      "Epoch 23/100\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.4376 - val_loss: 0.4296\n",
      "Epoch 24/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4295\n",
      "Epoch 25/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4296\n",
      "Epoch 26/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4295\n",
      "Epoch 27/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4299\n",
      "Epoch 28/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4295\n",
      "Epoch 29/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4298\n",
      "Epoch 30/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4297\n",
      "Epoch 31/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4295\n",
      "Epoch 32/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 33/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4302\n",
      "Epoch 34/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4297\n",
      "Epoch 35/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 36/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 37/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 38/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4376 - val_loss: 0.4293\n",
      "Epoch 39/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4298\n",
      "Epoch 40/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4293\n",
      "Epoch 41/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4293\n",
      "Epoch 42/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 43/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 44/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4299\n",
      "Epoch 45/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 46/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4298\n",
      "Epoch 47/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 48/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 49/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 50/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 51/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 52/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 53/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 54/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4293\n",
      "Epoch 55/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4293\n",
      "Epoch 56/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 57/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 58/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 59/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 60/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 61/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 62/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 63/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 64/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 65/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 66/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 67/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 68/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 69/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 70/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4295\n",
      "Epoch 71/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 72/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4298\n",
      "Epoch 73/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 74/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 75/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 76/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 77/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4297\n",
      "Epoch 78/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 79/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4295\n",
      "Epoch 80/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 81/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4295\n",
      "Epoch 82/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 83/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4295\n",
      "Epoch 84/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4293\n",
      "Epoch 85/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 86/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 87/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4296\n",
      "Epoch 88/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 89/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4294\n",
      "Epoch 90/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4296\n",
      "Epoch 91/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4375 - val_loss: 0.4296\n",
      "Epoch 92/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 93/100\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.4374 - val_loss: 0.4294\n",
      "Epoch 94/100\n",
      "  49/1094 [>.............................] - ETA: 5s - loss: 0.4301"
     ]
    }
   ],
   "source": [
    "\n",
    "# 拟合模型\n",
    "# Fit the model\n",
    "history = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=100, batch_size=32, verbose=1)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204d8553-9d57-422e-8056-bdb89dab3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 绘制损失曲线\n",
    "# Plot loss\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7fd0b-7be1-40f8-9b8b-a9916b25d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试集\n",
    "# Predict on test set\n",
    "test_predict = model.predict(testX)\n",
    "testY=testY.reshape(len(testY),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004c966-e827-48e8-ac81-3fe3710909a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#精度评价\n",
    "# Accuracy evaluation\n",
    "for i in range(8):\n",
    "    test_predict1=test_predict[:,i]\n",
    "    testY1= testY[:,i]\n",
    "    MSE = mean_squared_error(test_predict1, testY1)\n",
    "    print(\"Mean Squared Error for Column\", i + 1, \":\", MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2481f8-42f3-47cd-8a79-decd7cfc31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 3\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    f'/models/slot0/{model_version}/', # v1/models/slot0/为tensorflow-serving的模型根目录\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbffcd-807c-4690-9bf8-1172e3c53247",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_data = json.dumps({\n",
    "            'inputs': test_features.values[:1].tolist()\n",
    "        })  \n",
    "print(req_data)\n",
    "response = requests.post(f'http://fireeye-test-model-container:8501/v1/models/slot0/versions/{model_version}:predict', # 根据部署地址填写\n",
    "                         data=req_data,\n",
    "                         headers={\"content-type\": \"application/json\"})\n",
    "if response.status_code != 200:\n",
    "    raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "resp_data = json.loads(response.text)    \n",
    "if 'outputs' not in resp_data \\\n",
    "                    or type(resp_data['outputs']) is not list:\n",
    "    raise ValueError('Malformed tf-serving response')\n",
    "\n",
    "print(resp_data)\n",
    "print(\"{'outputs':\",test_labels.values[:1].tolist())\n",
    "\n",
    "print(\"y1 MSE:%.4f\" % mean_squared_error(test_labels.values[:1].tolist(), resp_data['outputs']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
